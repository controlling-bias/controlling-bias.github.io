---
layout: default
---

*   [<b>Data preprocessing to mitigate bias: A maximum entropy based approach</b>](https://arxiv.org/abs/1906.02164)\\
    L. Elisa Celis, Vijay Keswani, Nisheeth K. Vishnoi\\
    ICML 2020 [[blogpost]]() [[code]](https://github.com/vijaykeswani/Fair-Max-Entropy-Distributions)

*   [<b>Interventions for Ranking in the Presence of Implicit Bias</b>](https://arxiv.org/abs/2001.08767)\\
	L. Elisa Celis, Anay Mehrotra, Nisheeth K. Vishnoi\\
	ACM FAT* 2020

*	[<b>Assessing Social and Intersectional Biases in Contextualized Word Representations</b>](https://arxiv.org/abs/1911.01485)\\
	Yi Chern Tan, L. Elisa Celis\\
	NeurIPS 2019

*	[<b>Coresets for clustering with fairness constraints</b>](https://arxiv.org/abs/1906.08484)\\
	Lingxiao Huang, Shaofeng Jiang, Nisheeth K. Vishnoi\\
	NeurIPS 2019

*	[<b>Towards controlling discrimination in online ad auctions</b>](https://arxiv.org/abs/1901.10450)\\
	L. Elisa Celis, Anay Mehrotra, Nisheeth K. Vishnoi\\
	ICML 2019 [[demo]](https://fair-online-advertising.herokuapp.com/) [[blogpost]](http://cs.yale.edu/bias/blog/jekyll/update/2019/02/08/fair-advertising.html) [[code]](https://github.com/AnayMehrotra/Fair-Online-Advertising)

*	[<b>Stable and Fair Classification</b>](https://arxiv.org/abs/1902.07823)\\
	Lingxiao Huang, Nisheeth K. Vishnoi\\
	ICML 2019 [[demo]](https://fair-voting-demo.herokuapp.com/) [[blogpost]](http://cs.yale.edu/bias/blog/jekyll/update/2018/09/10/multiwinner-elections.html) 

*   <b>A Dashboard for Controlling Polarization in Personalization</b>\\
	L. Elisa Celis, Sayash Kapoor, Farnood Salehi, Vijay Keswani, Nisheeth K. Vishnoi\\
    AI Communications 2019 [[demo]](https://fair-personalized-news.herokuapp.com/fast/diversity.php) [[blogpost]](http://cs.yale.edu/bias/blog/jekyll/update/2018/01/20/balanced-news-search.html) 

*	[<b>Controlling polarization in personalization</b>](http://arxiv.org/abs/1802.08674)\\
	L. Elisa Celis, Sayash Kapoor, Farnood Salehi, Nisheeth K. Vishnoi\\
	Best technical paper - ACM FAT* 2019

*   [<b>Classification with Fairness Constraints: A Meta-Algorithm with Provable Guarantees</b>](https://arxiv.org/abs/1802.04023)\\
	L. Elisa Celis, Lingxiao Huang, Vijay Keswani and Nisheeth K. Vishnoi\\
    ACM-FAT* 2019 [[blogpost]](http://cs.yale.edu/bias/blog/jekyll/update/2018/11/06/fair-classification.html) [[code]](https://github.com/vijaykeswani/FairClassification)

*   [<b>Fair and Diverse DPP-based Data Summarization</b>](https://arxiv.org/abs/1802.04023)\\
    L. Elisa Celis, Vijay Keswani, Damian Straszak, Amit Deshpande, Tarun Kathuria, Nisheeth K. Vishnoi\\
    ICML 2018 [[demo]](https://fair-image-search.herokuapp.com/imageDiversity.php) [[code]](https://github.com/DamianStraszak/FairDiverseDPPSampling)

*	[<b>Multiwinner voting with fairness constraints</b>](http://arxiv.org/abs/1710.10057)\\
	L. Elisa Celis, Lingxiao Huang, Nisheeth K. Vishnoi\\
	IJCAI-ECAI 2018 [[demo]](https://fair-voting-demo.herokuapp.com/) [[blogpost]](http://cs.yale.edu/bias/blog/jekyll/update/2018/09/10/multiwinner-elections.html) [[code]](https://github.com/huanglx12/Balanced-Committee-Election)

*	[<b>Ranking with Fairness Constraints</b>](https://arxiv.org/abs/1704.06840)\\
	L. Elisa Celis, Damian Straszak, Nisheeth K. Vishnoi\\
	ICALP 2018 [[demo]](http://balanced-ranking.herokuapp.com/) [[blogpost]](http://cs.yale.edu/bias/blog/jekyll/update/2018/11/03/balanced-ranking.html)

*	[<b>Fair Personalization</b>](http://arxiv.org/abs/1707.02260)\\
	L. Elisa Celis, Nisheeth K. Vishnoi\\
	FAT-ML 2017

*	[<b>How to be fair and diverse?</b>](https://arxiv.org/abs/1610.07183)\\
	L. Elisa Celis, Amit Deshpande, Tarun Kathuria, Nisheeth K. Vishnoi\\
	FAT-ML 2016

